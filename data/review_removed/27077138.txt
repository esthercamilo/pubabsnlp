{'Year': '2014', 'Month': 'Aug'}
Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing.
We initiate the study of privacy in pharmacogenetics, wherein machine learning models are used to guide medical treatments based on a patient's genotype and background. Performing an in-depth case study on privacy in personalized warfarin dosing, we show that suggested models carry privacy risks, in particular because attackers can perform what we call <i>model inversion</i>: an attacker, given the model and some demographic information about a patient, can predict the patient's genetic markers. As differential privacy (DP) is an oft-proposed solution for medical settings such as this, we evaluate its effectiveness for building private versions of pharmacogenetic models. We show that <i>DP mechanisms prevent our model inversion attacks when the privacy budget is carefully selected</i>. We go on to analyze the impact on utility by performing simulated clinical trials with DP dosing models. We find that for privacy budgets effective at preventing attacks, <i>patients would be exposed to increased risk of stroke, bleeding events, and mortality</i>. We conclude that <i>current</i> DP mechanisms do not simultaneously improve genomic privacy while retaining desirable clinical efficacy, highlighting the need for new mechanisms that should be evaluated <i>in situ</i> using the general methodology introduced by our work.